{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \ndf=pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\nprint(df.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for finding path\nimport os\n\nfor root, dirs, files in os.walk(\"/kaggle/input\"):\n    for file in files:\n        print(os.path.join(root, file))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T21:38:32.379215Z","iopub.execute_input":"2025-11-20T21:38:32.379487Z","iopub.status.idle":"2025-11-20T21:38:32.387868Z","shell.execute_reply.started":"2025-11-20T21:38:32.379459Z","shell.execute_reply":"2025-11-20T21:38:32.386832Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = df.select_dtypes(include=['object', 'category']).columns\ndf[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\ndf[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.get_dummies(df,columns=['Sex'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nnumeric_cols=df.select_dtypes(include=['int64','float64']).columns\nfor col in numeric_cols:\n    plt.figure(figsize=(6,4))\n    sns.boxplot(x=df[col])\n    plt.title(f'Boxplot of {col}')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n\nfor col in numeric_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n\n    lower = Q1 - 1.5*IQR\n    upper = Q3 + 1.5*IQR\n\n    df[col] = df[col].clip(lower, upper)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nnumeric_cols=df.select_dtypes(include=['int64','float64']).columns\nfor col in numeric_cols:\n    plt.figure(figsize=(6,4))\n    sns.boxplot(x=df[col])\n    plt.title(f'Boxplot of {col}')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_cols = df.select_dtypes(include=['object','category']).columns\n\ndf = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n\ndf = df.astype({col: int for col in df.columns if df[col].dtype == 'bool'})\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_cols = df.select_dtypes(include=['int64','float64']).columns\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndf[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df.drop(['Status_C', 'Status_CL', 'Status_D'], axis=1)\n\ny = df[['Status_C', 'Status_CL', 'Status_D']].idxmax(axis=1)\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,    # 20% test data\n    random_state=42,  # ensures reproducibility\n    stratify=y        \n)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(X_train,y_train)\ny_pred=model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# THIS IS FINAL CODE FOR EVERY PROBLEM;\n# USE THIS CODE ONLY;\n\n\n\nimport pandas as pd \ndf=pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\nprint(df.head())\ndf.isnull().sum()\nnumeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = df.select_dtypes(include=['object', 'category']).columns\ndf[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\ndf[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\ndf=pd.get_dummies(df,columns=['Sex'])\nprint(df.head())\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nnumeric_cols=df.select_dtypes(include=['int64','float64']).columns\nfor col in numeric_cols:\n    plt.figure(figsize=(6,4))\n    sns.boxplot(x=df[col])\n    plt.title(f'Boxplot of {col}')\n    plt.show()\n    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n\nfor col in numeric_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n\n    lower = Q1 - 1.5*IQR\n    upper = Q3 + 1.5*IQR\n\n    df[col] = df[col].clip(lower, upper)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nnumeric_cols=df.select_dtypes(include=['int64','float64']).columns\nfor col in numeric_cols:\n    plt.figure(figsize=(6,4))\n    sns.boxplot(x=df[col])\n    plt.title(f'Boxplot of {col}')\n    plt.show()\n    df.head()\n    categorical_cols = df.select_dtypes(include=['object','category']).columns\n\ndf = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n\ndf = df.astype({col: int for col in df.columns if df[col].dtype == 'bool'})\ndf.head()\nnumeric_cols = df.select_dtypes(include=['int64','float64']).columns\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndf[numeric_cols] = scaler.fit_transform(df[numeric_cols])\ndf.head()\nX = df.drop(['Status_C', 'Status_CL', 'Status_D'], axis=1)\n\ny = df[['Status_C', 'Status_CL', 'Status_D']].idxmax(axis=1)\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,    # 20% test data\n    random_state=42,  # ensures reproducibility\n    stratify=y        \n)\n\nX_train\n\nfrom sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(X_train,y_train)\ny_pred=model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== IMPORTS ============================\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# ===================== LOAD DATA ==========================\ndf = pd.read_csv(\"/kaggle/input/mock-test-2-mse-2/train.csv\")\nprint(df.head())\n\n# ===================== MISSING VALUE CHECK =================\ndf.isnull().sum()\n\n# ===================== MISSING VALUE FILL ==================\nnumeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\ncategorical_cols = df.select_dtypes(include=['object', 'category']).columns\n\ndf[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\ndf[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n\n# ===================== ENCODING ============================\ndf = pd.get_dummies(df, columns=['Sex'])\nprint(df.head())\n\n# ===================== EXTRA EDA (ADDED) ====================\n\n# Heatmap\nplt.figure(figsize=(10,6))\nsns.heatmap(df.corr(), cmap='coolwarm')\nplt.title(\"Correlation Heatmap\")\nplt.show()\n\n# KDE Plots\nfor col in numeric_cols:\n    plt.figure(figsize=(6,4))\n    sns.kdeplot(df[col])\n    plt.title(f\"KDE Plot of {col}\")\n    plt.show()\n\n# Pairplot\nsns.pairplot(df[numeric_cols], diag_kind='kde')\nplt.show()\n\n# ===================== BOXPLOTS BEFORE CAPPING ==============\nnumeric_cols=df.select_dtypes(include=['int64','float64']).columns\nfor col in numeric_cols:\n    plt.figure(figsize=(6,4))\n    sns.boxplot(x=df[col])\n    plt.title(f'Boxplot of {col}')\n    plt.show()\n\n# ===================== OUTLIER CAPPING ======================\nnumeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n\nfor col in numeric_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n\n    lower = Q1 - 1.5*IQR\n    upper = Q3 + 1.5*IQR\n\n    df[col] = df[col].clip(lower, upper)\n\n# ===================== BOXPLOTS AFTER CAPPING ===============\nnumeric_cols=df.select_dtypes(include=['int64','float64']).columns\nfor col in numeric_cols:\n    plt.figure(figsize=(6,4))\n    sns.boxplot(x=df[col])\n    plt.title(f'Boxplot of {col}')\n    plt.show()\n\n# ===================== SECOND ENCODING =======================\ncategorical_cols = df.select_dtypes(include=['object','category']).columns\ndf = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\ndf = df.astype({col: int for col in df.columns if df[col].dtype == 'bool'})\n\n# ===================== SCALING ===============================\nnumeric_cols = df.select_dtypes(include=['int64','float64']).columns\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n\n# ===================== TRAIN-TEST SPLIT ======================\nX = df.drop(['Status_C', 'Status_CL', 'Status_D'], axis=1)\ny = df[['Status_C', 'Status_CL', 'Status_D']].idxmax(axis=1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# ===================== MODEL TRAINING ========================\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# ===================== ACCURACY ==============================\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\n# ===================== CLASSIFICATION REPORT (ADDED) =========\nfrom sklearn.metrics import classification_report\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}